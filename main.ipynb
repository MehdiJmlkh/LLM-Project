{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880446cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor, LlavaForConditionalGeneration\n",
    "from PIL import Image\n",
    "import torch\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "# Load model and processor\n",
    "model_id = \"llava-hf/llava-1.5-7b-hf\"\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "model = LlavaForConditionalGeneration.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# Load image from a URL\n",
    "image_url = \"https://upload.wikimedia.org/wikipedia/commons/thumb/9/99/Black_and_white_cat.jpg/640px-Black_and_white_cat.jpg\"\n",
    "response = requests.get(image_url)\n",
    "image = Image.open(BytesIO(response.content))\n",
    "\n",
    "# Define your prompt\n",
    "prompt = \"Describe the image in detail.\"\n",
    "\n",
    "# Prepare input\n",
    "inputs = processor(prompt, image, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "# Generate output\n",
    "output = model.generate(**inputs, max_new_tokens=150)\n",
    "\n",
    "# Decode and print\n",
    "result = processor.decode(output[0], skip_special_tokens=True)\n",
    "print(\"LLaVA Output:\", result)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
